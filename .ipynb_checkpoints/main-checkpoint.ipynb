{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2840,
     "status": "ok",
     "timestamp": 1574708262548,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "p-BI8gkj4Hp1",
    "outputId": "41d1274b-cd51-44ee-c4af-d81bd53a67c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "#!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2770,
     "status": "ok",
     "timestamp": 1574708262552,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "RgeWVKN94HqN",
    "outputId": "4eab332c-1b01-4e9b-bb3f-d9ea7befc86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 260341 characters\n",
      "Let the suicide doors up\n",
      "I threw suicides on the tour bus\n",
      "I threw suicides on the private jet\n",
      "You know what that mean, I'm fly to death\n",
      "I step in Def Jam buildin' like I'm the shit\n",
      "Tell 'em give me fifty million or I'ma quit\n",
      "Most rappers' taste level\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open('kanye_verses.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2670,
     "status": "ok",
     "timestamp": 1574708262555,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "8HzRqvHK4Hqd",
    "outputId": "fd5d512a-3cc1-48b5-d5b5-e421b25f0fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 unique characters:\n",
      "['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '·', 'Á', 'é', 'í', 'ñ', 'ó', 'ā', '\\u200b', '–', '‘', '’', '“', '”', '…']\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, 'a': 55, 'b': 56, 'c': 57, 'd': 58, 'e': 59, 'f': 60, 'g': 61, 'h': 62, 'i': 63, 'j': 64, 'k': 65, 'l': 66, 'm': 67, 'n': 68, 'o': 69, 'p': 70, 'q': 71, 'r': 72, 's': 73, 't': 74, 'u': 75, 'v': 76, 'w': 77, 'x': 78, 'y': 79, 'z': 80, '~': 81, '·': 82, 'Á': 83, 'é': 84, 'í': 85, 'ñ': 86, 'ó': 87, 'ā': 88, '\\u200b': 89, '–': 90, '‘': 91, '’': 92, '“': 93, '”': 94, '…': 95}\n"
     ]
    }
   ],
   "source": [
    "# number of unique characters \n",
    "print(len(set(text)),'unique characters:') \n",
    "\n",
    "# dict of these characters\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "\n",
    "char_dict = {char:i for i,char in enumerate(chars)}\n",
    "idx2char = np.array(chars)\n",
    "print(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2552,
     "status": "ok",
     "timestamp": 1574708262558,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "V78sCket4Hqr",
    "outputId": "f2b83a6f-b0fb-4670-9f3f-937a11d8b0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the suici\n",
      "[40 59 74  1 74 62 59  1 73 75 63 57 63]\n",
      "'Let the suici' ---- characters mapped to int ---- > [40 59 74  1 74 62 59  1 73 75 63 57 63]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([40, 59, 74, ..., 75, 14, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequence of the text\n",
    "text_in_num =np.array([char_dict[i] for i in text])\n",
    "print(text[:13])\n",
    "print(text_in_num[:13])\n",
    "\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_in_num[:13]))\n",
    "text_in_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2650,
     "status": "ok",
     "timestamp": 1574708262748,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "J35F4NZx4Hq2",
    "outputId": "3b8869d7-d3a9-47db-d156-7c5935cc9da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to trainable data\n",
    "seq_len = 50\n",
    "example_per_epoc = len(text_in_num)//(seq_len+1)\n",
    "example_per_epoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1574708262751,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "JPSeMcEG4HrI",
    "outputId": "1da38800-f716-4f85-a76c-929f327d2e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "e\n",
      "t\n",
      " \n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_in_num)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2559,
     "status": "ok",
     "timestamp": 1574708262754,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "sGAW7OOL4HrT",
    "outputId": "bcc4177f-ce60-4ad8-b1cb-f64ef0be27df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Let the suicide doors up\\nI threw suicides on the to'\n",
      "'ur bus\\nI threw suicides on the private jet\\nYou know'\n",
      "\" what that mean, I'm fly to death\\nI step in Def Jam\"\n",
      "\" buildin' like I'm the shit\\nTell 'em give me fifty \"\n",
      "\"million or I'ma quit\\nMost rappers' taste level ain'\"\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjizZxG44Hre"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1574708262913,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "ynOc_FYQ4Hrm",
    "outputId": "1d29b4ed-c6f8-466a-b22c-dd1885aac412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Let the suicide doors up\\nI threw suicides on the t'\n",
      "Target data: 'et the suicide doors up\\nI threw suicides on the to'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2448,
     "status": "ok",
     "timestamp": 1574708262915,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "JohbSppn4Hrw",
    "outputId": "5e8ec872-1b0f-432e-957b-efc869ba3a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 40 ('L')\n",
      "  expected output: 59 ('e')\n",
      "Step    1\n",
      "  input: 59 ('e')\n",
      "  expected output: 74 ('t')\n",
      "Step    2\n",
      "  input: 74 ('t')\n",
      "  expected output: 1 (' ')\n",
      "Step    3\n",
      "  input: 1 (' ')\n",
      "  expected output: 74 ('t')\n",
      "Step    4\n",
      "  input: 74 ('t')\n",
      "  expected output: 62 ('h')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2432,
     "status": "ok",
     "timestamp": 1574708262917,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "rVZsMEEd4Hr9",
    "outputId": "a8e8b2fe-df84-4e54-c7fd-763b889b8bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 50), (64, 50)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fy4n3BOo4HsJ"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTY2zdCW4HsY"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size = len(chars),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3919,
     "status": "ok",
     "timestamp": 1574708264456,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "zCugZKN84Hsq",
    "outputId": "2a79096e-e61c-4f75-f7fe-59b6d0091f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 96) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3903,
     "status": "ok",
     "timestamp": 1574708264458,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "Nymmt3PB4Hs5",
    "outputId": "9397c98f-aa45-4c46-a2d6-b4a29fe78f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           24576     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 96)            98400     \n",
      "=================================================================\n",
      "Total params: 4,061,280\n",
      "Trainable params: 4,061,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZB1SSHgu4HtL"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3871,
     "status": "ok",
     "timestamp": 1574708264462,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "nEZgHiHC4Htc",
    "outputId": "0ed2f97c-23bc-4ea3-f0b1-4f4d2e8d5e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 76, 67, 67,  5, 43, 27, 36,  7, 95, 15, 13, 88, 22, 71, 27, 75,\n",
       "       62,  3, 27, 74, 46, 94, 30, 62, 35, 63, 77, 52, 59, 56, 60, 58, 16,\n",
       "        2, 63, 27, 20, 26, 75, 68, 53, 29, 21, 62, 61, 83, 69,  0, 22],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3854,
     "status": "ok",
     "timestamp": 1574708264464,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "IwKSSQ724Hts",
    "outputId": "028058e8-1d85-49a4-f12e-1a8e037b90f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ld about a friend of mine\\nThis little light of min'\n",
      "\n",
      "Next Char Predictions: \n",
      " '–vmm$O;H\\'…/-ā6q;uh\";tR”BhGiwXebfd0!i;4:unYA5hgÁo\\n6'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3837,
     "status": "ok",
     "timestamp": 1574708264466,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "3gFfNnen4Ht-",
    "outputId": "fcda876b-bb38-4163-fd35-ad66b53167b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 50, 96)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.5641265\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxrHj8Lr4HuM"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpj3eGgK4Huo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpj3eGgK4Huo"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTwlReiJ4HvI"
   },
   "outputs": [],
   "source": [
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2204718,
     "status": "ok",
     "timestamp": 1574714443040,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "Zg7rc4n54Hvl",
    "outputId": "b5574e20-5303-40bb-ef8d-fa17f5a2c8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "79/79 [==============================] - 211s 3s/step - loss: 3.1952\n",
      "Epoch 2/30\n",
      "79/79 [==============================] - 211s 3s/step - loss: 2.3643\n",
      "Epoch 3/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 2.1844\n",
      "Epoch 4/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 2.0349\n",
      "Epoch 5/30\n",
      "79/79 [==============================] - 206s 3s/step - loss: 1.9179\n",
      "Epoch 6/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 1.8223\n",
      "Epoch 7/30\n",
      "79/79 [==============================] - 208s 3s/step - loss: 1.7432\n",
      "Epoch 8/30\n",
      "79/79 [==============================] - 207s 3s/step - loss: 1.6738\n",
      "Epoch 9/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 1.6086\n",
      "Epoch 10/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 1.5513\n",
      "Epoch 11/30\n",
      "79/79 [==============================] - 206s 3s/step - loss: 1.4937\n",
      "Epoch 12/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 1.4387\n",
      "Epoch 13/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 1.3814\n",
      "Epoch 14/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 1.3236\n",
      "Epoch 15/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 1.2593\n",
      "Epoch 16/30\n",
      "79/79 [==============================] - 206s 3s/step - loss: 1.1943\n",
      "Epoch 17/30\n",
      "79/79 [==============================] - 215s 3s/step - loss: 1.1264\n",
      "Epoch 18/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 1.0585\n",
      "Epoch 19/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 0.9862\n",
      "Epoch 20/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 0.9206\n",
      "Epoch 21/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 0.8506\n",
      "Epoch 22/30\n",
      "79/79 [==============================] - 217s 3s/step - loss: 0.7875\n",
      "Epoch 23/30\n",
      "79/79 [==============================] - 203s 3s/step - loss: 0.7332\n",
      "Epoch 24/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 0.6840\n",
      "Epoch 25/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 0.6376\n",
      "Epoch 26/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 0.6002\n",
      "Epoch 27/30\n",
      "79/79 [==============================] - 205s 3s/step - loss: 0.5730\n",
      "Epoch 28/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 0.5426\n",
      "Epoch 29/30\n",
      "79/79 [==============================] - 204s 3s/step - loss: 0.5203\n",
      "Epoch 30/30\n",
      "79/79 [==============================] - 202s 3s/step - loss: 0.5008\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1574714443054,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "hm5jePC54Hvx",
    "outputId": "1eb24c77-9757-4124-b8e8-5450a51a4a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQQUxgeG4Hv7"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1574714443551,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "pYKWK-nb4HwJ",
    "outputId": "c0521733-268f-45fa-e489-4def611f7fde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            24576     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 96)             98400     \n",
      "=================================================================\n",
      "Total params: 4,061,280\n",
      "Trainable params: 4,061,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WbqXYtu4Hwb"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char_dict[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5999,
     "status": "ok",
     "timestamp": 1574714837975,
     "user": {
      "displayName": "Fred Yen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6nxbYGKaquw4vPrPGHaR1suwnJn5ef6C6H-HZBw=s64",
      "userId": "05465226488795521239"
     },
     "user_tz": 360
    },
    "id": "k_BN2bzK4Hwl",
    "outputId": "eb184d15-c6cb-4748-ee83-99a5b892a4c4"
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=\"Superman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6iJX90G4Hwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvHwqkki4HxA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
